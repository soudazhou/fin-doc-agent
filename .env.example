# =============================================================================
# Financial Document Q&A Agent — Environment Configuration
# =============================================================================
#
# Copy this file to .env and fill in your API keys:
#   cp .env.example .env
#
# Values are loaded by Pydantic Settings (app/config.py).
# Any setting can be overridden via environment variables.
# =============================================================================

# =============================================================================
# REQUIRED: API Keys
# =============================================================================

# Anthropic — Used for Claude LLM (default provider for reasoning)
# Get yours at: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-...

# OpenAI — Used for embeddings (text-embedding-3-small) by default
# Get yours at: https://platform.openai.com/api-keys
# NOTE: Not needed if using Alibaba Cloud for embeddings (see Preset 7 below)
OPENAI_API_KEY=sk-...

# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Uncomment ONE preset below. Default: Anthropic Claude.
#
# Each preset sets:
#   LLM_PROVIDER    — "anthropic" or "openai_compatible"
#   LLM_BASE_URL    — API endpoint (only for openai_compatible)
#   LLM_API_KEY     — Overrides provider-specific key (optional)
#   LLM_MODEL       — Model identifier
#
# For /compare endpoint, provider IDs use the format:
#   "anthropic/claude-sonnet-4-6"
#   "openai_compatible/deepseek-chat@https://api.deepseek.com/v1"
# =============================================================================

# --- Preset 1: Anthropic Claude (DEFAULT) ---
# Best quality. $3.00/1M input tokens. Recommended for demos.
LLM_PROVIDER=anthropic
LLM_MODEL=claude-sonnet-4-6

# --- Preset 2: DeepSeek V3 ---
# Cheapest flagship. $0.14/1M input tokens. 20x cheaper than Claude.
# Great for development iteration.
# LLM_PROVIDER=openai_compatible
# LLM_BASE_URL=https://api.deepseek.com/v1
# LLM_API_KEY=sk-...  # DeepSeek API key
# LLM_MODEL=deepseek-chat

# --- Preset 3: DeepSeek R1 (Reasoning) ---
# Chain-of-thought reasoning model. $0.55/1M input tokens.
# Best for complex multi-step financial analysis.
# LLM_PROVIDER=openai_compatible
# LLM_BASE_URL=https://api.deepseek.com/v1
# LLM_API_KEY=sk-...  # DeepSeek API key
# LLM_MODEL=deepseek-reasoner

# --- Preset 4: Qwen 3.5-Plus (Alibaba Cloud) ---
# Cheapest flagship model. $0.11/1M input tokens.
# LLM_PROVIDER=openai_compatible
# LLM_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# LLM_API_KEY=sk-...  # DashScope API key
# LLM_MODEL=qwen-plus

# --- Preset 5: GLM-5 (Zhipu AI) ---
# MIT licensed, self-hostable. $1.00/1M input tokens.
# LLM_PROVIDER=openai_compatible
# LLM_BASE_URL=https://open.bigmodel.cn/api/paas/v4
# LLM_API_KEY=...  # Zhipu API key
# LLM_MODEL=glm-5

# --- Preset 6: MiniMax M2.5 ---
# 3rd globally on SWE-bench. $0.20/1M input tokens.
# LLM_PROVIDER=openai_compatible
# LLM_BASE_URL=https://api.minimax.chat/v1
# LLM_API_KEY=...  # MiniMax API key
# LLM_MODEL=minimax-m2.5

# --- Preset 7: Alibaba Cloud (All-in-One) ---
# Use ONE DashScope API key for both LLM and embeddings.
# Supports Qwen, DeepSeek, GLM, Kimi — all through one account.
# Get your key at: https://bailian.console.alibabacloud.com/?tab=model#/api-key
#
# LLM_PROVIDER=openai_compatible
# LLM_BASE_URL=https://dashscope-intl.aliyuncs.com/compatible-mode/v1
# LLM_API_KEY=sk-...  # DashScope API key (used for both LLM and embeddings)
# LLM_MODEL=qwen-plus
# EMBEDDING_MODEL=text-embedding-v3
# EMBEDDING_DIMENSIONS=1536
# EMBEDDING_BASE_URL=https://dashscope-intl.aliyuncs.com/compatible-mode/v1
# OPENAI_API_KEY=  # Not needed — LLM_API_KEY is used as fallback

# =============================================================================
# LLM Parameters
# =============================================================================

LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=4096

# =============================================================================
# Database — PostgreSQL + pgvector
# =============================================================================
# Defaults match docker-compose.yml. Override for external databases.

DATABASE_URL=postgresql+asyncpg://finagent:finagent_dev@localhost:5432/fin_doc_agent
DATABASE_URL_SYNC=postgresql+psycopg2://finagent:finagent_dev@localhost:5432/fin_doc_agent

# =============================================================================
# Redis
# =============================================================================
# db 0 = Celery broker, db 1 = Celery results, db 2 = rate limiting

REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/1

# =============================================================================
# Vector Store
# =============================================================================
# "pgvector" (default, uses PostgreSQL) or "chroma" (in-process)

VECTORSTORE_TYPE=pgvector

# =============================================================================
# Embedding Configuration
# =============================================================================
# Default: OpenAI text-embedding-3-small.
# Set EMBEDDING_BASE_URL to use an OpenAI-compatible provider instead
# (e.g. Alibaba Cloud DashScope, see Preset 7 above).
# When EMBEDDING_BASE_URL is set, OPENAI_API_KEY is not required —
# the embedder falls back to LLM_API_KEY.

EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536
# EMBEDDING_BASE_URL=  # Leave unset for OpenAI, or set to compatible endpoint

# =============================================================================
# Chunking Configuration
# =============================================================================
# Token-based chunking. Benchmark with 256/512/1024 via /benchmark/retrieval.

CHUNK_SIZE=512
CHUNK_OVERLAP=50

# =============================================================================
# Retrieval Configuration
# =============================================================================

RETRIEVAL_TOP_K=5
RETRIEVAL_SIMILARITY_THRESHOLD=0.7
MAX_SEARCH_ITERATIONS=3

# =============================================================================
# Evaluation Configuration
# =============================================================================

EVAL_JUDGE_MODEL=gpt-4.1
EVAL_DEFAULT_THRESHOLD=0.7

# =============================================================================
# Authorisation
# =============================================================================
# Set AUTH_ENABLED=true for production. Default false for local dev.
# ADMIN_BOOTSTRAP_KEY: Set this to create the first admin API key
# without needing an existing key (chicken-and-egg problem).

AUTH_ENABLED=false
RATE_LIMIT_RPM=100
AUDIT_LOGGING_ENABLED=true
RATE_LIMIT_REDIS_URL=redis://localhost:6379/2
# ADMIN_BOOTSTRAP_KEY=your-bootstrap-secret
