# =============================================================================
# Environment Variables — Financial Document Q&A Agent
# =============================================================================
#
# Copy this file to `.env` and fill in your API keys:
#   cp .env.example .env
#
# IMPORTANT: Never commit your .env file! It contains secrets.
# The .gitignore is already configured to exclude it.
# =============================================================================

# --- Application ---
APP_NAME="Financial Document Q&A Agent"
APP_VERSION="0.1.0"
DEBUG=true

# --- Database (PostgreSQL + pgvector) ---
# These defaults match the docker-compose.yml configuration.
# Change these if you're using an external database.
DATABASE_URL="postgresql+asyncpg://finagent:finagent_dev@localhost:5432/fin_doc_agent"
DATABASE_URL_SYNC="postgresql+psycopg2://finagent:finagent_dev@localhost:5432/fin_doc_agent"

# --- Redis ---
# Used as Celery broker (db 0) and result backend (db 1)
REDIS_URL="redis://localhost:6379/0"
CELERY_BROKER_URL="redis://localhost:6379/0"
CELERY_RESULT_BACKEND="redis://localhost:6379/1"

# --- API Keys (REQUIRED — get these from the provider dashboards) ---
# Anthropic: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY="your-anthropic-api-key-here"

# OpenAI (used ONLY for embeddings): https://platform.openai.com/api-keys
OPENAI_API_KEY="your-openai-api-key-here"

# --- Embedding Configuration ---
EMBEDDING_MODEL="text-embedding-3-small"
EMBEDDING_DIMENSIONS=1536

# --- LLM Configuration (Multi-Provider) ---
# Switch between providers by changing these values. No code changes needed.
#
# Option 1: Claude (best quality, for demos/interviews)
LLM_PROVIDER="anthropic"
LLM_MODEL="claude-sonnet-4-6"
# LLM_BASE_URL=         # Not needed for Anthropic
# LLM_API_KEY=          # Uses ANTHROPIC_API_KEY by default
#
# Option 2: DeepSeek V3 (best price/performance, for development)
# LLM_PROVIDER="openai_compatible"
# LLM_BASE_URL="https://api.deepseek.com/v1"
# LLM_API_KEY="your-deepseek-api-key"
# LLM_MODEL="deepseek-chat"
#
# Option 3: DeepSeek R1 (reasoning model, for complex analysis)
# LLM_PROVIDER="openai_compatible"
# LLM_BASE_URL="https://api.deepseek.com/v1"
# LLM_API_KEY="your-deepseek-api-key"
# LLM_MODEL="deepseek-reasoner"
#
# Option 4: Qwen 3.5-Plus (cheapest flagship)
# LLM_PROVIDER="openai_compatible"
# LLM_BASE_URL="https://dashscope.aliyuncs.com/compatible-mode/v1"
# LLM_API_KEY="your-qwen-api-key"
# LLM_MODEL="qwen-plus"
#
# Option 5: GLM-5 (MIT licensed, self-hostable)
# LLM_PROVIDER="openai_compatible"
# LLM_BASE_URL="https://open.bigmodel.cn/api/paas/v4"
# LLM_API_KEY="your-zhipu-api-key"
# LLM_MODEL="glm-5"
#
# Option 6: MiniMax M2.5 (3rd globally on SWE-bench, $0.20/1M)
# LLM_PROVIDER="openai_compatible"
# LLM_BASE_URL="https://api.minimax.chat/v1"
# LLM_API_KEY="your-minimax-api-key"
# LLM_MODEL="MiniMax-M2.5"

LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=4096

# --- Chunking Configuration ---
CHUNK_SIZE=512
CHUNK_OVERLAP=50

# --- Retrieval Configuration ---
RETRIEVAL_TOP_K=5
RETRIEVAL_SIMILARITY_THRESHOLD=0.7
